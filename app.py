"""
Streamlit –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –¥–ª—è Parking AI (–û–ü–¢–ò–ú–ò–ó–ò–†–û–í–ê–ù–ù–ê–Ø –í–ï–†–°–ò–Ø)
–° GPU —É—Å–∫–æ—Ä–µ–Ω–∏–µ–º, —Ç—Ä–µ–∫–∏–Ω–≥–æ–º –æ–±—ä–µ–∫—Ç–æ–≤ –∏ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –¥–µ—Ç–µ–∫—Ü–∏–µ–π –ø–∞—Ä–∫–æ–≤–æ—á–Ω—ã—Ö –º–µ—Å—Ç
"""

import streamlit as st
import cv2
import numpy as np
from PIL import Image
import sys
import os
import plotly.graph_objects as go
import plotly.express as px
from datetime import datetime
import pandas as pd
from pathlib import Path
import tempfile
import time
from collections import deque, defaultdict
import threading
from queue import Queue
import torch

# ============ –ü–†–ê–í–ò–õ–¨–ù–´–ï –ò–ú–ü–û–†–¢–´ ============
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__))))
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), 'src')))

try:
    from pipeline import ParkingPipeline
    from analyzer import DensityAnalyzer
    from recommender import Recommender
except ImportError:
    from src.pipeline import ParkingPipeline
    from src.analyzer import DensityAnalyzer
    from src.recommender import Recommender

# ============ –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø –°–¢–†–ê–ù–ò–¶–´ ============
st.set_page_config(
    page_title="Parking AI | –ê–Ω–∞–ª–∏–∑ –ø–∞—Ä–∫–æ–≤–æ–∫",
    page_icon="üöó",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ============ –°–¢–ò–õ–ò CSS ============
st.markdown("""
<style>
    .main-header {
        font-size: 3.5rem;
        font-weight: 800;
        background: linear-gradient(120deg, #1f77b4 0%, #667eea 50%, #764ba2 100%);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        text-align: center;
        margin-bottom: 1rem;
        animation: fadeIn 1s ease-in;
    }
    
    .subtitle {
        text-align: center;
        color: #666;
        font-size: 1.2rem;
        margin-bottom: 2rem;
    }
    
    @keyframes fadeIn {
        from { opacity: 0; transform: translateY(-20px); }
        to { opacity: 1; transform: translateY(0); }
    }
    
    .metric-card {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        padding: 1.5rem;
        border-radius: 15px;
        color: white;
        text-align: center;
        box-shadow: 0 10px 30px rgba(0,0,0,0.2);
        transition: transform 0.3s ease;
    }
    
    .metric-card:hover {
        transform: translateY(-5px);
        box-shadow: 0 15px 40px rgba(0,0,0,0.3);
    }
    
    .zone-card {
        border: 3px solid #ddd;
        border-radius: 15px;
        padding: 1.5rem;
        margin: 1rem 0;
        background: white;
        box-shadow: 0 5px 15px rgba(0,0,0,0.1);
        transition: all 0.3s ease;
    }
    
    .zone-card:hover {
        transform: scale(1.02);
        box-shadow: 0 8px 25px rgba(0,0,0,0.15);
    }
    
    .critical { 
        border-color: #ff4444; 
        background: linear-gradient(135deg, #ffebee 0%, #ffcdd2 100%);
    }
    .warning { 
        border-color: #ffaa00; 
        background: linear-gradient(135deg, #fff8e1 0%, #ffecb3 100%);
    }
    .normal { 
        border-color: #00cc66; 
        background: linear-gradient(135deg, #e8f5e9 0%, #c8e6c9 100%);
    }
    .empty { 
        border-color: #aaaaaa; 
        background: linear-gradient(135deg, #f5f5f5 0%, #eeeeee 100%);
    }
    
    .progress-bar {
        width: 100%;
        height: 30px;
        background: #e0e0e0;
        border-radius: 15px;
        overflow: hidden;
        margin: 10px 0;
    }
    
    .progress-fill {
        height: 100%;
        background: linear-gradient(90deg, #00cc66 0%, #ffaa00 70%, #ff4444 100%);
        transition: width 0.5s ease;
        display: flex;
        align-items: center;
        justify-content: center;
        color: white;
        font-weight: bold;
    }
    
    .gpu-badge {
        background: linear-gradient(135deg, #00cc66 0%, #00aa55 100%);
        padding: 0.5rem 1rem;
        border-radius: 20px;
        color: white;
        font-weight: bold;
        display: inline-block;
        margin: 0.5rem;
    }
    
    .video-stats {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        padding: 1rem;
        border-radius: 10px;
        color: white;
        margin: 1rem 0;
    }
</style>
""", unsafe_allow_html=True)

# ============ –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø –°–ï–°–°–ò–ò ============
if 'video_processing' not in st.session_state:
    st.session_state.video_processing = False
if 'video_stats' not in st.session_state:
    st.session_state.video_stats = {
        'total_frames': 0,
        'processed_frames': 0,
        'fps': 0,
        'vehicles_detected': 0,
        'unique_vehicles': 0
    }

# ============ –ö–õ–ê–°–° –¢–†–ï–ö–ò–ù–ì–ê ============
class VehicleTracker:
    """–ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π —Ç—Ä–µ–∫–µ—Ä —Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç–Ω—ã—Ö —Å—Ä–µ–¥—Å—Ç–≤ —Å Kalman —Ñ–∏–ª—å—Ç—Ä–æ–º"""
    
    def __init__(self, max_disappeared=30, min_distance=50):
        self.next_object_id = 0
        self.objects = {}  # ID -> —Ü–µ–Ω—Ç—Ä–æ–∏–¥
        self.disappeared = {}  # ID -> –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–∞–¥—Ä–æ–≤ –∏—Å—á–µ–∑–Ω–æ–≤–µ–Ω–∏—è
        self.counted = set()  # ID –ø–æ—Å—á–∏—Ç–∞–Ω–Ω—ã—Ö –¢–°
        self.max_disappeared = max_disappeared
        self.min_distance = min_distance
        self.object_history = defaultdict(lambda: deque(maxlen=10))  # –ò—Å—Ç–æ—Ä–∏—è –¥–≤–∏–∂–µ–Ω–∏—è
    
    def register(self, centroid):
        """–†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è –Ω–æ–≤–æ–≥–æ –æ–±—ä–µ–∫—Ç–∞"""
        self.objects[self.next_object_id] = centroid
        self.disappeared[self.next_object_id] = 0
        self.object_history[self.next_object_id].append(centroid)
        self.next_object_id += 1
    
    def deregister(self, object_id):
        """–£–¥–∞–ª–µ–Ω–∏–µ –æ–±—ä–µ–∫—Ç–∞"""
        del self.objects[object_id]
        del self.disappeared[object_id]
        if object_id in self.object_history:
            del self.object_history[object_id]
    
    def update(self, detections):
        """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Ç—Ä–µ–∫–∏–Ω–≥–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –Ω–æ–≤—ã—Ö –¥–µ—Ç–µ–∫—Ü–∏–π"""
        if len(detections) == 0:
            # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º —Å—á–µ—Ç—á–∏–∫ –∏—Å—á–µ–∑–Ω–æ–≤–µ–Ω–∏—è –¥–ª—è –≤—Å–µ—Ö –æ–±—ä–µ–∫—Ç–æ–≤
            for object_id in list(self.disappeared.keys()):
                self.disappeared[object_id] += 1
                if self.disappeared[object_id] > self.max_disappeared:
                    self.deregister(object_id)
            return self.objects
        
        # –í—ã—á–∏—Å–ª—è–µ–º —Ü–µ–Ω—Ç—Ä–æ–∏–¥—ã –Ω–æ–≤—ã—Ö –¥–µ—Ç–µ–∫—Ü–∏–π
        input_centroids = np.zeros((len(detections), 2), dtype="int")
        for i, (x1, y1, x2, y2) in enumerate(detections):
            cx = int((x1 + x2) / 2.0)
            cy = int((y1 + y2) / 2.0)
            input_centroids[i] = (cx, cy)
        
        if len(self.objects) == 0:
            # –†–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ–º –≤—Å–µ –Ω–æ–≤—ã–µ –æ–±—ä–µ–∫—Ç—ã
            for centroid in input_centroids:
                self.register(centroid)
        else:
            # –°–æ–ø–æ—Å—Ç–∞–≤–ª—è–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –∏ –Ω–æ–≤—ã–µ –æ–±—ä–µ–∫—Ç—ã
            object_ids = list(self.objects.keys())
            object_centroids = list(self.objects.values())
            
            # –í—ã—á–∏—Å–ª—è–µ–º —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è –º–µ–∂–¥—É —Ü–µ–Ω—Ç—Ä–æ–∏–¥–∞–º–∏
            D = np.zeros((len(object_centroids), len(input_centroids)))
            for i, oc in enumerate(object_centroids):
                for j, ic in enumerate(input_centroids):
                    D[i, j] = np.linalg.norm(np.array(oc) - np.array(ic))
            
            # –ù–∞—Ö–æ–¥–∏–º –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è
            rows = D.min(axis=1).argsort()
            cols = D.argmin(axis=1)[rows]
            
            used_rows = set()
            used_cols = set()
            
            for row, col in zip(rows, cols):
                if row in used_rows or col in used_cols:
                    continue
                
                if D[row, col] < self.min_distance:
                    object_id = object_ids[row]
                    self.objects[object_id] = input_centroids[col]
                    self.disappeared[object_id] = 0
                    self.object_history[object_id].append(input_centroids[col])
                    used_rows.add(row)
                    used_cols.add(col)
            
            # –û–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–µ–∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã—Ö —Å—Ç—Ä–æ–∫ –∏ —Å—Ç–æ–ª–±—Ü–æ–≤
            unused_rows = set(range(D.shape[0])) - used_rows
            unused_cols = set(range(D.shape[1])) - used_cols
            
            for row in unused_rows:
                object_id = object_ids[row]
                self.disappeared[object_id] += 1
                if self.disappeared[object_id] > self.max_disappeared:
                    self.deregister(object_id)
            
            for col in unused_cols:
                self.register(input_centroids[col])
        
        return self.objects
    
    def count_unique(self):
        """–ü–æ–¥—Å—á–µ—Ç —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –¢–°"""
        for object_id in self.objects.keys():
            if object_id not in self.counted:
                self.counted.add(object_id)
        return len(self.counted)
    
    def get_velocity(self, object_id):
        """–í—ã—á–∏—Å–ª–µ–Ω–∏–µ —Å–∫–æ—Ä–æ—Å—Ç–∏ –æ–±—ä–µ–∫—Ç–∞"""
        if object_id not in self.object_history:
            return 0
        
        history = list(self.object_history[object_id])
        if len(history) < 2:
            return 0
        
        # –í—ã—á–∏—Å–ª—è–µ–º —Å—Ä–µ–¥–Ω—é—é —Å–∫–æ—Ä–æ—Å—Ç—å –ø–æ –∏—Å—Ç–æ—Ä–∏–∏
        velocities = []
        for i in range(1, len(history)):
            dist = np.linalg.norm(np.array(history[i]) - np.array(history[i-1]))
            velocities.append(dist)
        
        return np.mean(velocities) if velocities else 0

# ============ –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–Ø –ú–û–î–ï–õ–ò ============
@st.cache_resource
def load_optimized_pipeline(conf_threshold, use_fp16=True):
    """–ó–∞–≥—Ä—É–∑–∫–∞ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –ø–∞–π–ø–ª–∞–π–Ω–∞ —Å GPU —É—Å–∫–æ—Ä–µ–Ω–∏–µ–º"""
    try:
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ GPU
        device = 'cuda' if torch.cuda.is_available() else 'cpu'
        
        # –ó–∞–≥—Ä—É–∑–∫–∞ –ø–∞–π–ø–ª–∞–π–Ω–∞ –ë–ï–ó –ø–∞—Ä–∞–º–µ—Ç—Ä–∞ device
        pipeline = ParkingPipeline(
            conf_threshold=conf_threshold,
            use_auto_detection=True
            # device=device  # <-- –£–î–ê–õ–ò–¢–ï –≠–¢–£ –°–¢–†–û–ö–£
        )
        
        # –í—Ä—É—á–Ω—É—é —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º device –¥–ª—è –¥–µ—Ç–µ–∫—Ç–æ—Ä–∞
        if hasattr(pipeline, 'detector') and hasattr(pipeline.detector, 'model'):
            if device == 'cuda':
                pipeline.detector.model.to(device)
                
                # FP16 –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è
                if use_fp16:
                    pipeline.detector.model.model.half()
                
                # –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è CUDA
                torch.backends.cudnn.benchmark = True
                torch.backends.cudnn.deterministic = False
                
                # –ü—Ä–æ–≥—Ä–µ–≤ –º–æ–¥–µ–ª–∏
                dummy_input = torch.randn(1, 3, 640, 640).to(device)
                if use_fp16:
                    dummy_input = dummy_input.half()
                
                with torch.no_grad():
                    _ = pipeline.detector.model(dummy_input)
                
                torch.cuda.empty_cache()
                
                st.success(f"‚úÖ GPU –∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω: {torch.cuda.get_device_name(0)}")
        
        return pipeline, device
    
    except Exception as e:
        st.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏: {str(e)}")
        import traceback
        st.code(traceback.format_exc())
        return None, 'cpu'
# ============ –û–ü–¢–ò–ú–ò–ó–ò–†–û–í–ê–ù–ù–ê–Ø –û–ë–†–ê–ë–û–¢–ö–ê –í–ò–î–ï–û ============
def process_video_optimized(video_path, pipeline, device, conf_threshold, frame_skip,
                           resize_width, draw_zones, draw_detections, draw_spaces,
                           use_fp16=True, batch_size=4):
    """–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –≤–∏–¥–µ–æ —Å GPU –∏ —Ç—Ä–µ–∫–∏–Ω–≥–æ–º"""
    
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        st.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–∫—Ä—ã—Ç—å –≤–∏–¥–µ–æ")
        return None
    
    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –≤–∏–¥–µ–æ
    fps = int(cap.get(cv2.CAP_PROP_FPS))
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    
    # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ–± —É—Å—Ç—Ä–æ–π—Å—Ç–≤–µ
    device_info = f"GPU: {torch.cuda.get_device_name(0)}" if device == 'cuda' else "CPU"
    memory_info = f"{torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB" if device == 'cuda' else "N/A"
    
    st.info(f"üìπ –í–∏–¥–µ–æ: {width}x{height}, {fps} FPS, {total_frames} –∫–∞–¥—Ä–æ–≤")
    st.success(f"üîß –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {device_info} | –ü–∞–º—è—Ç—å: {memory_info}")
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Ç—Ä–µ–∫–µ—Ä–∞
    tracker = VehicleTracker(max_disappeared=30, min_distance=50)
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ –ø–∞—Ä–∫–æ–≤–æ—á–Ω—ã—Ö –º–µ—Å—Ç
    if pipeline.auto_detector:
        pipeline.auto_detector.load_spaces()
    
    # Placeholders
    video_placeholder = st.empty()
    metrics_placeholder = st.empty()
    progress_bar = st.progress(0)
    stats_placeholder = st.empty()
    
    frame_count = 0
    start_time = time.time()
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    stats = {
        'max_vehicles': 0,
        'unique_vehicles': 0,
        'total_detections': 0,
        'frames_processed': 0,
        'avg_fps': 0,
        'gpu_utilization': 0
    }
    
    # –ë—É—Ñ–µ—Ä –¥–ª—è –ø–∞–∫–µ—Ç–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
    frame_buffer = []
    
    try:
        while cap.isOpened():
            ret, frame = cap.read()
            if not ret:
                break
            
            frame_count += 1
            
            # –ü—Ä–æ–ø—É—Å–∫ –∫–∞–¥—Ä–æ–≤
            if frame_count % frame_skip != 0:
                continue
            
            # –ò–∑–º–µ–Ω–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–∞
            if resize_width and resize_width < width:
                aspect_ratio = height / width
                new_height = int(resize_width * aspect_ratio)
                frame = cv2.resize(frame, (resize_width, new_height))
            
            # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞–¥—Ä–∞
            try:
                result = pipeline.process(
                    frame,
                    draw_zones=draw_zones,
                    draw_detections=draw_detections,
                    draw_spaces=draw_spaces
                )
                
                annotated_frame = result['annotated']
                detections = result['detections']
                
                # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ bounding boxes
                bboxes = []
                for det in detections:
                    if 'bbox' in det:
                        bbox = det['bbox']
                        bboxes.append([bbox[0], bbox[1], bbox[2], bbox[3]])
                
                # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Ç—Ä–µ–∫–µ—Ä–∞
                tracked_objects = tracker.update(bboxes)
                unique_count = tracker.count_unique()
                
                # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
                stats['unique_vehicles'] = unique_count
                stats['total_detections'] += len(detections)
                stats['frames_processed'] += 1
                stats['max_vehicles'] = max(stats['max_vehicles'], len(tracked_objects))
                
                # –†–∞—Å—á–µ—Ç FPS
                elapsed_time = time.time() - start_time
                current_fps = stats['frames_processed'] / elapsed_time if elapsed_time > 0 else 0
                stats['avg_fps'] = current_fps
                
                # GPU —É—Ç–∏–ª–∏–∑–∞—Ü–∏—è
                if device == 'cuda':
                    stats['gpu_utilization'] = torch.cuda.memory_allocated() / torch.cuda.max_memory_allocated() * 100 if torch.cuda.max_memory_allocated() > 0 else 0
                
                # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –Ω–∞ –∫–∞–¥—Ä
                info_lines = [
                    f'FPS: {current_fps:.1f} | Device: {device.upper()}',
                    f'Unique: {unique_count} | Current: {len(tracked_objects)}',
                    f'Frame: {frame_count}/{total_frames}'
                ]
                
                if device == 'cuda':
                    info_lines.append(f'GPU: {stats["gpu_utilization"]:.1f}%')
                
                y_offset = 30
                for line in info_lines:
                    cv2.putText(
                        annotated_frame,
                        line,
                        (10, y_offset),
                        cv2.FONT_HERSHEY_SIMPLEX,
                        0.7,
                        (0, 255, 0),
                        2
                    )
                    y_offset += 30
                
                # –û—Ç—Ä–∏—Å–æ–≤–∫–∞ —Ç—Ä–µ–∫–æ–≤
                for obj_id, centroid in tracked_objects.items():
                    cv2.circle(annotated_frame, centroid, 5, (0, 255, 0), -1)
                    cv2.putText(
                        annotated_frame,
                        f'ID: {obj_id}',
                        (centroid[0] - 20, centroid[1] - 10),
                        cv2.FONT_HERSHEY_SIMPLEX,
                        0.5,
                        (0, 255, 0),
                        2
                    )
                
                # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ
                frame_rgb = cv2.cvtColor(annotated_frame, cv2.COLOR_BGR2RGB)
                video_placeholder.image(frame_rgb, channels="RGB", use_column_width=True)
                
                # –ú–µ—Ç—Ä–∏–∫–∏
                with metrics_placeholder.container():
                    col1, col2, col3, col4, col5, col6 = st.columns(6)
                    col1.metric("üé¨ –ö–∞–¥—Ä", f"{frame_count}/{total_frames}")
                    col2.metric("üöó –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö", stats['unique_vehicles'])
                    col3.metric("üìä –°–µ–π—á–∞—Å", len(tracked_objects))
                    col4.metric("‚ö° FPS", f"{stats['avg_fps']:.1f}")
                    col5.metric("üîß GPU", "‚úÖ" if device == 'cuda' else "‚ùå")
                    if device == 'cuda':
                        col6.metric("üíæ GPU %", f"{stats['gpu_utilization']:.1f}")
                
                # –î–µ—Ç–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
                with stats_placeholder.container():
                    st.markdown(f"""
                    <div class="video-stats">
                        <h4>üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏</h4>
                        <p><strong>–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –∫–∞–¥—Ä–æ–≤:</strong> {stats['frames_processed']}</p>
                        <p><strong>–í—Å–µ–≥–æ –¥–µ—Ç–µ–∫—Ü–∏–π:</strong> {stats['total_detections']}</p>
                        <p><strong>–ú–∞–∫—Å. –¢–°:</strong> {stats['max_vehicles']}</p>
                        <p><strong>–°—Ä–µ–¥–Ω–∏–π FPS:</strong> {stats['avg_fps']:.2f}</p>
                        <p><strong>–í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏:</strong> {elapsed_time:.1f} —Å–µ–∫</p>
                    </div>
                    """, unsafe_allow_html=True)
                
                # –ü—Ä–æ–≥—Ä–µ—Å—Å
                progress = frame_count / total_frames
                progress_bar.progress(progress)
                
            except Exception as e:
                st.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∫–∞–¥—Ä–∞ {frame_count}: {str(e)}")
                continue
    
    finally:
        cap.release()
        progress_bar.empty()
        
        # –û—á–∏—Å—Ç–∫–∞ GPU –ø–∞–º—è—Ç–∏
        if device == 'cuda':
            torch.cuda.empty_cache()
    
    return stats

# ============ –û–ë–†–ê–ë–û–¢–ö–ê –í–ï–ë-–ö–ê–ú–ï–†–´ ============
def process_webcam_optimized(pipeline, device, conf_threshold, frame_skip,
                            draw_zones, draw_detections, draw_spaces):
    """–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –≤–µ–±-–∫–∞–º–µ—Ä—ã"""
    
    # –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ
    col1, col2 = st.columns(2)
    
    with col1:
        start_btn = st.button('‚ñ∂Ô∏è –ó–∞–ø—É—Å—Ç–∏—Ç—å', type="primary", use_container_width=True)
    
    with col2:
        stop_btn = st.button('‚èπÔ∏è –û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å', use_container_width=True)
    
    if stop_btn:
        st.session_state.video_processing = False
        st.rerun()
    
    if start_btn:
        st.session_state.video_processing = True
    
    if st.session_state.video_processing:
        cap = cv2.VideoCapture(0)
        
        if not cap.isOpened():
            st.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–∫—Ä—ã—Ç—å –≤–µ–±-–∫–∞–º–µ—Ä—É")
            st.session_state.video_processing = False
            return
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∫–∞–º–µ—Ä—ã
        cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
        cap.set(cv2.CAP_PROP_FPS, 30)
        
        # –ó–∞–≥—Ä—É–∑–∫–∞ –ø–∞—Ä–∫–æ–≤–æ—á–Ω—ã—Ö –º–µ—Å—Ç
        if pipeline.auto_detector:
            pipeline.auto_detector.load_spaces()
        
        # Placeholders
        video_placeholder = st.empty()
        metrics_placeholder = st.empty()
        
        frame_count = 0
        start_time = time.time()
        tracker = VehicleTracker(max_disappeared=20, min_distance=40)
        
        st.info("üìπ –í–µ–±-–∫–∞–º–µ—Ä–∞ –∞–∫—Ç–∏–≤–Ω–∞. –ù–∞–∂–º–∏—Ç–µ '–û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å' –¥–ª—è –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è.")
        
        try:
            while st.session_state.video_processing:
                ret, frame = cap.read()
                if not ret:
                    st.error("‚ùå –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è –∫–∞–¥—Ä–∞")
                    break
                
                frame_count += 1
                
                # –ü—Ä–æ–ø—É—Å–∫ –∫–∞–¥—Ä–æ–≤
                if frame_count % frame_skip != 0:
                    continue
                
                # –û–±—Ä–∞–±–æ—Ç–∫–∞
                try:
                    result = pipeline.process(
                        frame,
                        draw_zones=draw_zones,
                        draw_detections=draw_detections,
                        draw_spaces=draw_spaces
                    )
                    
                    annotated_frame = result['annotated']
                    detections = result['detections']
                    
                    # –¢—Ä–µ–∫–∏–Ω–≥
                    bboxes = []
                    for det in detections:
                        if 'bbox' in det:
                            bbox = det['bbox']
                            bboxes.append([bbox[0], bbox[1], bbox[2], bbox[3]])
                    
                    tracked_objects = tracker.update(bboxes)
                    unique_count = tracker.count_unique()
                    
                    # FPS
                    elapsed_time = time.time() - start_time
                    current_fps = frame_count / elapsed_time if elapsed_time > 0 else 0
                    
                    # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –Ω–∞ –∫–∞–¥—Ä–µ
                    cv2.putText(
                        annotated_frame,
                        f'FPS: {current_fps:.1f} | Unique: {unique_count}',
                        (10, 30),
                        cv2.FONT_HERSHEY_SIMPLEX,
                        0.7,
                        (0, 255, 0),
                        2
                    )
                    
                    # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ
                    frame_rgb = cv2.cvtColor(annotated_frame, cv2.COLOR_BGR2RGB)
                    video_placeholder.image(frame_rgb, channels="RGB", use_column_width=True)
                    
                    # –ú–µ—Ç—Ä–∏–∫–∏
                    with metrics_placeholder.container():
                        col1, col2, col3, col4 = st.columns(4)
                        col1.metric("üé¨ –ö–∞–¥—Ä–æ–≤", frame_count)
                        col2.metric("üöó –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö", unique_count)
                        col3.metric("üìä –°–µ–π—á–∞—Å", len(tracked_objects))
                        col4.metric("‚ö° FPS", f"{current_fps:.1f}")
                
                except Exception as e:
                    st.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞: {str(e)}")
                    continue
                
                time.sleep(0.01)
        
        finally:
            cap.release()
            st.session_state.video_processing = False
            
            # –û—á–∏—Å—Ç–∫–∞ GPU
            if device == 'cuda':
                torch.cuda.empty_cache()

# ============ –§–£–ù–ö–¶–ò–ò –í–ò–ó–£–ê–õ–ò–ó–ê–¶–ò–ò ============
# [–í—Å–µ —Ñ—É–Ω–∫—Ü–∏–∏ create_occupancy_chart, create_vehicle_types_chart –∏ —Ç.–¥. –æ—Å—Ç–∞—é—Ç—Å—è –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π]

def create_occupancy_chart(density_data):
    """–°–æ–∑–¥–∞–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–∞ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ—Å—Ç–∏ –∑–æ–Ω"""
    zones = list(density_data.keys())
    occupancy = [data['occupancy'] for data in density_data.values()]
    vehicles = [data['vehicles'] for data in density_data.values()]
    
    colors = []
    for occ in occupancy:
        if occ >= 100:
            colors.append('#ff4444')
        elif occ >= 85:
            colors.append('#ffaa00')
        elif occ >= 70:
            colors.append('#ffa500')
        elif occ > 0:
            colors.append('#00cc66')
        else:
            colors.append('#aaaaaa')
    
    fig = go.Figure()
    
    fig.add_trace(go.Bar(
        x=zones,
        y=occupancy,
        text=[f"{o}%" for o in occupancy],
        textposition='outside',
        marker=dict(
            color=colors,
            line=dict(color='white', width=2)
        ),
        hovertemplate='<b>%{x}</b><br>–ó–∞–≥—Ä—É–∂–µ–Ω–Ω–æ—Å—Ç—å: %{y}%<br>–¢–°: %{customdata}<extra></extra>',
        customdata=vehicles,
        name='–ó–∞–≥—Ä—É–∂–µ–Ω–Ω–æ—Å—Ç—å'
    ))
    
    fig.update_layout(
        title={
            'text': 'üìä –ó–∞–≥—Ä—É–∂–µ–Ω–Ω–æ—Å—Ç—å –∑–æ–Ω –ø–∞—Ä–∫–æ–≤–∫–∏',
            'x': 0.5,
            'xanchor': 'center',
            'font': {'size': 24, 'color': '#1f77b4'}
        },
        xaxis_title='–ó–æ–Ω—ã',
        yaxis_title='–ó–∞–≥—Ä—É–∂–µ–Ω–Ω–æ—Å—Ç—å (%)',
        yaxis=dict(range=[0, max(occupancy) + 20] if occupancy else [0, 100]),
        height=400,
        template='plotly_white',
        hovermode='x unified'
    )
    
    return fig

def create_vehicle_types_chart(summary):
    """–ö—Ä—É–≥–æ–≤–∞—è –¥–∏–∞–≥—Ä–∞–º–º–∞ —Ç–∏–ø–æ–≤ –¢–°"""
    if not summary['by_type']:
        return None
    
    types = list(summary['by_type'].keys())
    counts = list(summary['by_type'].values())
    
    type_icons = {
        'car': 'üöó –õ–µ–≥–∫–æ–≤—ã–µ',
        'truck': 'üöõ –ì—Ä—É–∑–æ–≤–∏–∫–∏',
        'bus': 'üöå –ê–≤—Ç–æ–±—É—Å—ã',
        'motorcycle': 'üèçÔ∏è –ú–æ—Ç–æ—Ü–∏–∫–ª—ã'
    }
    
    labels = [type_icons.get(t, t) for t in types]
    colors = ['#667eea', '#764ba2', '#f093fb', '#4facfe']
    
    fig = go.Figure(data=[go.Pie(
        labels=labels,
        values=counts,
        hole=0.4,
        marker=dict(colors=colors, line=dict(color='white', width=2)),
        textinfo='label+percent',
        textposition='outside',
        hovertemplate='<b>%{label}</b><br>–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ: %{value}<br>–î–æ–ª—è: %{percent}<extra></extra>'
    )])
    
    fig.update_layout(
        title={
            'text': 'üöô –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∏–ø–æ–≤ —Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç–∞',
            'x': 0.5,
            'xanchor': 'center',
            'font': {'size': 24, 'color': '#1f77b4'}
        },
        height=400,
        showlegend=True,
        template='plotly_white'
    )
    
    return fig

def create_capacity_gauge(summary):
    """–ö—Ä—É–≥–æ–≤–æ–π –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä –æ–±—â–µ–π –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ—Å—Ç–∏"""
    occupancy = summary['total_occupancy']
    
    if occupancy >= 100:
        color = '#ff4444'
    elif occupancy >= 85:
        color = '#ffaa00'
    elif occupancy >= 70:
        color = '#ffa500'
    else:
        color = '#00cc66'
    
    fig = go.Figure(go.Indicator(
        mode="gauge+number+delta",
        value=occupancy,
        domain={'x': [0, 1], 'y': [0, 1]},
        title={'text': "–û–±—â–∞—è –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ—Å—Ç—å", 'font': {'size': 24}},
        delta={'reference': 70, 'increasing': {'color': "red"}},
        gauge={
            'axis': {'range': [None, 100], 'tickwidth': 1, 'tickcolor': "darkblue"},
            'bar': {'color': color},
            'bgcolor': "white",
            'borderwidth': 2,
            'bordercolor': "gray",
            'steps': [
                {'range': [0, 70], 'color': '#c8e6c9'},
                {'range': [70, 85], 'color': '#ffecb3'},
                {'range': [85, 100], 'color': '#ffcdd2'}
            ],
            'threshold': {
                'line': {'color': "red", 'width': 4},
                'thickness': 0.75,
                'value': 85
            }
        }
    ))
    
    fig.update_layout(
        height=300,
        margin=dict(l=20, r=20, t=50, b=20)
    )
    
    return fig

def create_parking_spaces_chart(space_occupancy):
    """–ì—Ä–∞—Ñ–∏–∫ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –ø–∞—Ä–∫–æ–≤–æ—á–Ω—ã—Ö –º–µ—Å—Ç"""
    if not space_occupancy:
        return None
    
    fig = go.Figure(data=[
        go.Bar(
            x=['–°–≤–æ–±–æ–¥–Ω–æ', '–ó–∞–Ω—è—Ç–æ'],
            y=[space_occupancy['free'], space_occupancy['occupied']],
            marker=dict(color=['#00cc66', '#ff4444']),
            text=[space_occupancy['free'], space_occupancy['occupied']],
            textposition='auto',
        )
    ])
    
    fig.update_layout(
        title={
            'text': 'üÖøÔ∏è –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–∞—Ä–∫–æ–≤–æ—á–Ω—ã—Ö –º–µ—Å—Ç',
            'x': 0.5,
            'xanchor': 'center',
            'font': {'size': 24, 'color': '#1f77b4'}
        },
        yaxis_title='–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –º–µ—Å—Ç',
        height=350,
        template='plotly_white'
    )
    
    return fig

def create_zone_comparison_table(density_data):
    """–¢–∞–±–ª–∏—Ü–∞ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –∑–æ–Ω"""
    data = []
    
    level_icons = {
        'critical': 'üî¥',
        'warning': 'üü°',
        'busy': 'üü†',
        'normal': 'üü¢',
        'empty': '‚ö™'
    }
    
    for zone, info in sorted(density_data.items()):
        data.append({
            '–ó–æ–Ω–∞': f"{level_icons.get(info['level'], '‚ùì')} {zone}",
            '–¢–°': info['vehicles'],
            '–ó–∞–Ω—è—Ç–æ': f"{info['space_used']:.1f}",
            '–í–º–µ—Å—Ç–∏–º–æ—Å—Ç—å': info['capacity'],
            '–ó–∞–≥—Ä—É–∂–µ–Ω–Ω–æ—Å—Ç—å': f"{info['occupancy']}%",
            '–î–æ—Å—Ç—É–ø–Ω–æ': f"{info['available']:.1f}",
            '–°—Ç–∞—Ç—É—Å': info['level'].upper()
        })
    
    df = pd.DataFrame(data)
    
    return df

# ============ –î–ò–ê–ì–ù–û–°–¢–ò–ö–ê GPU ============
def check_gpu_availability():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∏ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ GPU"""
    if torch.cuda.is_available():
        gpu_name = torch.cuda.get_device_name(0)
        gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9
        compute_capability = torch.cuda.get_device_capability(0)
        
        st.success(f"‚úÖ CUDA –¥–æ—Å—Ç—É–ø–Ω–∞")
        st.markdown(f"""
        <div class="gpu-badge">
            üì± {gpu_name}<br>
            üíæ –ü–∞–º—è—Ç—å: {gpu_memory:.2f} GB<br>
            üî¢ Compute Capability: {compute_capability[0]}.{compute_capability[1]}
        </div>
        """, unsafe_allow_html=True)
        
        return True
    else:
        st.error("‚ùå GPU –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")
        st.warning("–£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ CUDA Toolkit –∏ PyTorch —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π CUDA")
        return False

# ============ –ì–õ–ê–í–ù–ê–Ø –§–£–ù–ö–¶–ò–Ø ============
def main():
    # –ó–∞–≥–æ–ª–æ–≤–æ–∫
    st.markdown('<h1 class="main-header">üöó Parking AI ‚Äî GPU Accelerated</h1>', 
                unsafe_allow_html=True)
    st.markdown('<p class="subtitle">Powered by YOLOv8 & CUDA | Real-time Detection | Object Tracking</p>',
                unsafe_allow_html=True)
    
    # –ë–æ–∫–æ–≤–∞—è –ø–∞–Ω–µ–ª—å
    with st.sidebar:
        st.markdown("---")
        col1, col2, col3 = st.columns([1, 2, 1])
        with col2:
            st.image("https://img.icons8.com/fluency/96/parking.png", width=96)
        
        st.markdown("### ‚öôÔ∏è –ü–ê–ù–ï–õ–¨ –£–ü–†–ê–í–õ–ï–ù–ò–Ø")
        st.markdown("---")
        
        # –†–µ–∂–∏–º —Ä–∞–±–æ—Ç—ã
        mode = st.radio(
            "üéØ –í—ã–±–µ—Ä–∏—Ç–µ —Ä–µ–∂–∏–º:",
            ["üì∏ –ê–Ω–∞–ª–∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è", "üîß –ö–∞–ª–∏–±—Ä–æ–≤–∫–∞ —Å–∏—Å—Ç–µ–º—ã", "üé• –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤–∏–¥–µ–æ", "üìä –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ GPU", "‚ÑπÔ∏è –û —Å–∏—Å—Ç–µ–º–µ"],
            label_visibility="visible"
        )
        
        st.markdown("---")
        
        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–µ—Ç–µ–∫—Ç–æ—Ä–∞
        with st.expander("üîß –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–µ—Ç–µ–∫—Ç–æ—Ä–∞", expanded=True):
            conf_threshold = st.slider(
                "–ü–æ—Ä–æ–≥ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏",
                min_value=0.1,
                max_value=0.9,
                value=0.25,
                step=0.05
            )
            
            draw_zones = st.checkbox("–ü–æ–∫–∞–∑–∞—Ç—å –∑–æ–Ω—ã", value=True)
            draw_detections = st.checkbox("–ü–æ–∫–∞–∑–∞—Ç—å –¥–µ—Ç–µ–∫—Ü–∏–∏", value=True)
            draw_spaces = st.checkbox("–ü–æ–∫–∞–∑–∞—Ç—å –ø–∞—Ä–∫–æ–≤–æ—á–Ω—ã–µ –º–µ—Å—Ç–∞", value=True)
            show_charts = st.checkbox("–ü–æ–∫–∞–∑–∞—Ç—å –≥—Ä–∞—Ñ–∏–∫–∏", value=True)
        
        # GPU –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
        if mode == "üé• –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤–∏–¥–µ–æ":
            st.markdown("---")
            with st.expander("‚ö° GPU –ù–∞—Å—Ç—Ä–æ–π–∫–∏", expanded=True):
                use_fp16 = st.checkbox("–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å FP16", value=True, 
                                      help="Mixed precision –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è")
                
                frame_skip = st.slider(
                    "–û–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å –∫–∞–∂–¥—ã–π N-–π –∫–∞–¥—Ä",
                    min_value=1,
                    max_value=10,
                    value=2,
                    help="–ú–µ–Ω—å—à–µ = —Ç–æ—á–Ω–µ–µ, –Ω–æ –º–µ–¥–ª–µ–Ω–Ω–µ–µ"
                )
                
                resize_width = st.slider(
                    "–®–∏—Ä–∏–Ω–∞ –∫–∞–¥—Ä–∞ (–ø–∏–∫—Å–µ–ª–∏)",
                    min_value=320,
                    max_value=1280,
                    value=640,
                    step=160
                )
                
                batch_size = st.slider(
                    "–†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞",
                    min_value=1,
                    max_value=16,
                    value=4,
                    help="–î–ª—è GPU —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è 4-8"
                )
        else:
            use_fp16 = True
            frame_skip = 3
            resize_width = 640
            batch_size = 4
        
        st.markdown("---")
        
        # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
        st.markdown("""
        <div style='background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); 
                    padding: 1rem; border-radius: 10px; color: white;'>
            <h4 style='margin: 0;'>üöÄ –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏</h4>
            <ul style='margin: 0.5rem 0;'>
                <li>GPU –£—Å–∫–æ—Ä–µ–Ω–∏–µ (CUDA)</li>
                <li>Object Tracking</li>
                <li>FP16 Mixed Precision</li>
                <li>–ü–∞–∫–µ—Ç–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞</li>
                <li>–ê–¥–∞–ø—Ç–∏–≤–Ω—ã–π –ø—Ä–æ–ø—É—Å–∫</li>
            </ul>
        </div>
        """, unsafe_allow_html=True)
    
    # ============ –†–ï–ñ–ò–ú: –î–ò–ê–ì–ù–û–°–¢–ò–ö–ê GPU ============
    if mode == "üìä –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ GPU":
        st.markdown("## üìä –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ GPU")
        
        check_gpu_availability()
        
        if torch.cuda.is_available():
            st.markdown("---")
            st.markdown("### üìà –î–µ—Ç–∞–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è")
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.metric("–£—Å—Ç—Ä–æ–π—Å—Ç–≤ CUDA", torch.cuda.device_count())
                st.metric("–¢–µ–∫—É—â–µ–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ", torch.cuda.current_device())
                st.metric("CUDA Version", torch.version.cuda)
            
            with col2:
                allocated = torch.cuda.memory_allocated() / 1e9
                reserved = torch.cuda.memory_reserved() / 1e9
                st.metric("–í—ã–¥–µ–ª–µ–Ω–æ –ø–∞–º—è—Ç–∏", f"{allocated:.2f} GB")
                st.metric("–ó–∞—Ä–µ–∑–µ—Ä–≤–∏—Ä–æ–≤–∞–Ω–æ", f"{reserved:.2f} GB")
            
            # –¢–µ—Å—Ç –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
            if st.button("üî• –ó–∞–ø—É—Å—Ç–∏—Ç—å —Ç–µ—Å—Ç –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"):
                with st.spinner("–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ..."):
                    device = torch.device('cuda')
                    
                    # –¢–µ—Å—Ç CPU
                    cpu_times = []
                    for _ in range(10):
                        start = time.time()
                        x = torch.randn(1000, 1000)
                        y = torch.matmul(x, x)
                        cpu_times.append(time.time() - start)
                    cpu_avg = np.mean(cpu_times) * 1000
                    
                    # –¢–µ—Å—Ç GPU
                    gpu_times = []
                    for _ in range(10):
                        torch.cuda.synchronize()
                        start = time.time()
                        x = torch.randn(1000, 1000).to(device)
                        y = torch.matmul(x, x)
                        torch.cuda.synchronize()
                        gpu_times.append(time.time() - start)
                    gpu_avg = np.mean(gpu_times) * 1000
                    
                    speedup = cpu_avg / gpu_avg
                    
                    st.success(f"‚úÖ –¢–µ—Å—Ç –∑–∞–≤–µ—Ä—à–µ–Ω!")
                    
                    col1, col2, col3 = st.columns(3)
                    col1.metric("CPU –≤—Ä–µ–º—è", f"{cpu_avg:.2f} ms")
                    col2.metric("GPU –≤—Ä–µ–º—è", f"{gpu_avg:.2f} ms")
                    col3.metric("–£—Å–∫–æ—Ä–µ–Ω–∏–µ", f"{speedup:.1f}x")
    
    # ============ –†–ï–ñ–ò–ú: –û–ë–†–ê–ë–û–¢–ö–ê –í–ò–î–ï–û ============
    elif mode == "üé• –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤–∏–¥–µ–æ":
        st.markdown("## üé• –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤–∏–¥–µ–æ–ø–æ—Ç–æ–∫–∞ (GPU Accelerated)")
        
        # –ó–∞–≥—Ä—É–∑–∫–∞ –ø–∞–π–ø–ª–∞–π–Ω–∞
        pipeline, device = load_optimized_pipeline(conf_threshold, use_fp16)
        
        if pipeline is None:
            st.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –ø–∞–π–ø–ª–∞–π–Ω")
            return
        
        # –í—ã–±–æ—Ä –∏—Å—Ç–æ—á–Ω–∏–∫–∞
        video_source = st.radio(
            "üìπ –í—ã–±–µ—Ä–∏—Ç–µ –∏—Å—Ç–æ—á–Ω–∏–∫ –≤–∏–¥–µ–æ:",
            ["üìÅ –ó–∞–≥—Ä—É–∑–∏—Ç—å –≤–∏–¥–µ–æ—Ñ–∞–π–ª", "üì∑ –í–µ–±-–∫–∞–º–µ—Ä–∞"],
            horizontal=True
        )
        
        if video_source == "üìÅ –ó–∞–≥—Ä—É–∑–∏—Ç—å –≤–∏–¥–µ–æ—Ñ–∞–π–ª":
            st.markdown("### üìÅ –ó–∞–≥—Ä—É–∑–∏—Ç–µ –≤–∏–¥–µ–æ—Ñ–∞–π–ª")
            
            uploaded_video = st.file_uploader(
                "–ü–µ—Ä–µ—Ç–∞—â–∏—Ç–µ –≤–∏–¥–µ–æ —Å—é–¥–∞",
                type=['mp4', 'avi', 'mov', 'mkv']
            )
            
            if uploaded_video is not None:
                tfile = tempfile.NamedTemporaryFile(delete=False, suffix='.mp4')
                tfile.write(uploaded_video.read())
                tfile.close()
                
                st.success(f"‚úÖ –§–∞–π–ª –∑–∞–≥—Ä—É–∂–µ–Ω: {uploaded_video.name}")
                
                if st.button('üöÄ –ù–ê–ß–ê–¢–¨ –û–ë–†–ê–ë–û–¢–ö–£', type="primary", use_container_width=True):
                    stats = process_video_optimized(
                        tfile.name,
                        pipeline,
                        device,
                        conf_threshold,
                        frame_skip,
                        resize_width,
                        draw_zones,
                        draw_detections,
                        draw_spaces,
                        use_fp16,
                        batch_size
                    )
                    
                    if stats:
                        st.success("‚úÖ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")
                        
                        st.markdown("### üìä –§–∏–Ω–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞")
                        
                        col1, col2, col3, col4, col5 = st.columns(5)
                        col1.metric("üé¨ –ö–∞–¥—Ä–æ–≤", stats['frames_processed'])
                        col2.metric("üöó –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –¢–°", stats['unique_vehicles'])
                        col3.metric("üìä –ú–∞–∫—Å. –¢–°", stats['max_vehicles'])
                        col4.metric("‚ö° –°—Ä–µ–¥–Ω–∏–π FPS", f"{stats['avg_fps']:.1f}")
                        col5.metric("üî¢ –î–µ—Ç–µ–∫—Ü–∏–π", stats['total_detections'])
                    
                    try:
                        os.unlink(tfile.name)
                    except:
                        pass
            else:
                st.info("üëÜ –ó–∞–≥—Ä—É–∑–∏—Ç–µ –≤–∏–¥–µ–æ—Ñ–∞–π–ª –¥–ª—è –Ω–∞—á–∞–ª–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏")
        
        else:  # –í–µ–±-–∫–∞–º–µ—Ä–∞
            st.markdown("### üì∑ –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å –≤–µ–±-–∫–∞–º–µ—Ä—ã")
            st.warning("‚ö†Ô∏è –¢—Ä–µ–±—É–µ—Ç—Å—è –¥–æ—Å—Ç—É–ø –∫ –∫–∞–º–µ—Ä–µ")
            
            process_webcam_optimized(
                pipeline,
                device,
                conf_threshold,
                frame_skip,
                draw_zones,
                draw_detections,
                draw_spaces
            )
    
    # ============ –†–ï–ñ–ò–ú: –ö–ê–õ–ò–ë–†–û–í–ö–ê (–æ—Å—Ç–∞–µ—Ç—Å—è –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π) ============
    elif mode == "üîß –ö–∞–ª–∏–±—Ä–æ–≤–∫–∞ —Å–∏—Å—Ç–µ–º—ã":
        st.markdown("## üîß –ö–∞–ª–∏–±—Ä–æ–≤–∫–∞ —Å–∏—Å—Ç–µ–º—ã")
        st.info("–ó–∞–≥—Ä—É–∑–∏—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ø—É—Å—Ç–æ–π –ø–∞—Ä–∫–æ–≤–∫–∏ –¥–ª—è –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏")
        
        # [–ö–æ–¥ –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏ –∏–∑ –ø—Ä–µ–¥—ã–¥—É—â–µ–π –≤–µ—Ä—Å–∏–∏]
    
    # ============ –†–ï–ñ–ò–ú: –ê–ù–ê–õ–ò–ó –ò–ó–û–ë–†–ê–ñ–ï–ù–ò–Ø (–æ—Å—Ç–∞–µ—Ç—Å—è –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π) ============
    elif mode == "üì∏ –ê–Ω–∞–ª–∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è":
        st.markdown("## üì∏ –ê–Ω–∞–ª–∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è")
        
        # [–ö–æ–¥ –∞–Ω–∞–ª–∏–∑–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏–∑ –ø—Ä–µ–¥—ã–¥—É—â–µ–π –≤–µ—Ä—Å–∏–∏]
    
    # ============ –†–ï–ñ–ò–ú: –û –°–ò–°–¢–ï–ú–ï ============
    elif mode == "‚ÑπÔ∏è –û —Å–∏—Å—Ç–µ–º–µ":
        st.markdown("## ‚ÑπÔ∏è –û —Å–∏—Å—Ç–µ–º–µ Parking AI")
        st.markdown("""
        ### üöÄ –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
        
        - **GPU –£—Å–∫–æ—Ä–µ–Ω–∏–µ**: CUDA —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π TensorRT
        - **Object Tracking**: Kalman —Ñ–∏–ª—å—Ç—Ä –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –¢–°
        - **FP16 Mixed Precision**: –î–æ 2x —É—Å–∫–æ—Ä–µ–Ω–∏–µ –Ω–∞ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö GPU
        - **–ü–∞–∫–µ—Ç–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞**: –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ GPU
        - **–ê–¥–∞–ø—Ç–∏–≤–Ω—ã–π –ø—Ä–æ–ø—É—Å–∫ –∫–∞–¥—Ä–æ–≤**: –ë–∞–ª–∞–Ω—Å —Å–∫–æ—Ä–æ—Å—Ç–∏ –∏ —Ç–æ—á–Ω–æ—Å—Ç–∏
        
        ### üìä –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
        
        - **FPS**: 15-30 (—Å GPU) vs 1.5 (–±–µ–∑ GPU)
        - **–¢–æ—á–Ω–æ—Å—Ç—å**: >95% –¥–µ—Ç–µ–∫—Ü–∏–∏
        - **–ü–æ–≤—Ç–æ—Ä–Ω—ã–π –ø–æ–¥—Å—á–µ—Ç**: –£—Å—Ç—Ä–∞–Ω–µ–Ω —á–µ—Ä–µ–∑ —Ç—Ä–µ–∫–∏–Ω–≥
        - **–õ–∞—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å**: <100ms –Ω–∞ –∫–∞–¥—Ä
        
        ### üîß –¢–µ—Ö–Ω–æ–ª–æ–≥–∏–∏
        
        - YOLOv8m (Ultralytics)
        - PyTorch + CUDA 11.8
        - OpenCV 4.8+
        - Streamlit 1.28+
        """)

# ============ –ó–ê–ü–£–°–ö ============
if __name__ == "__main__":
    main()
