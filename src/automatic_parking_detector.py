"""
–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –¥–µ—Ç–µ–∫—Ç–æ—Ä –ø–∞—Ä–∫–æ–≤–æ—á–Ω—ã—Ö –º–µ—Å—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–∞–∑–º–µ—Ç–∫–∏
–ë–µ–∑ —Ä—É—á–Ω–æ–π —Ä–∞–∑–º–µ—Ç–∫–∏ - –ø–æ–ª–Ω–æ—Å—Ç—å—é –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ
"""

import cv2
import numpy as np
from pathlib import Path
import pickle
from sklearn.cluster import DBSCAN
from scipy.spatial import distance
import json

class AutomaticParkingDetector:
    """
    –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –ø–∞—Ä–∫–æ–≤–æ—á–Ω—ã—Ö –º–µ—Å—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ:
    - –î–µ—Ç–µ–∫—Ü–∏–∏ –ª–∏–Ω–∏–π —Ä–∞–∑–º–µ—Ç–∫–∏
    - –ì–µ–æ–º–µ—Ç—Ä–∏—á–µ—Å–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
    - –ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–∞
    """
    
    def __init__(self, config_path='config/auto_parking_config.json'):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –¥–µ—Ç–µ–∫—Ç–æ—Ä–∞
        
        Args:
            config_path: –ø—É—Ç—å –∫ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
        """
        self.config_path = Path(config_path)
        self.parking_spaces = []
        
        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–µ—Ç–µ–∫—Ü–∏–∏ –ª–∏–Ω–∏–π
        self.canny_low = 50
        self.canny_high = 150
        self.hough_threshold = 80
        self.hough_min_line_length = 100
        self.hough_max_line_gap = 10
        
        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–∞—Ä–∫–æ–≤–æ—á–Ω—ã—Ö –º–µ—Å—Ç
        self.typical_space_width = 250  # –ø–∏–∫—Å–µ–ª–µ–π (–ø—Ä–∏–º–µ—Ä–Ω–æ)
        self.typical_space_height = 500  # –ø–∏–∫—Å–µ–ª–µ–π (–ø—Ä–∏–º–µ—Ä–Ω–æ)
        self.min_space_width = 150
        self.max_space_width = 400
        
        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏
        self.dbscan_eps = 30
        self.dbscan_min_samples = 2
        
        self.load_config()
    
    def load_config(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –∏–∑ —Ñ–∞–π–ª–∞"""
        if self.config_path.exists():
            try:
                with open(self.config_path, 'r') as f:
                    config = json.load(f)
                    self.canny_low = config.get('canny_low', self.canny_low)
                    self.canny_high = config.get('canny_high', self.canny_high)
                    self.hough_threshold = config.get('hough_threshold', self.hough_threshold)
                    self.typical_space_width = config.get('typical_space_width', self.typical_space_width)
                    self.typical_space_height = config.get('typical_space_height', self.typical_space_height)
                print(f"‚úÖ –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –∏–∑ {self.config_path}")
            except Exception as e:
                print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏: {e}")
    
    def save_config(self):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ç–µ–∫—É—â–µ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏"""
        self.config_path.parent.mkdir(parents=True, exist_ok=True)
        config = {
            'canny_low': self.canny_low,
            'canny_high': self.canny_high,
            'hough_threshold': self.hough_threshold,
            'hough_min_line_length': self.hough_min_line_length,
            'hough_max_line_gap': self.hough_max_line_gap,
            'typical_space_width': self.typical_space_width,
            'typical_space_height': self.typical_space_height,
            'dbscan_eps': self.dbscan_eps,
            'dbscan_min_samples': self.dbscan_min_samples
        }
        with open(self.config_path, 'w') as f:
            json.dump(config, f, indent=4)
        print(f"‚úÖ –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ {self.config_path}")
    
    def detect_parking_lines(self, image):
        """
        –î–µ—Ç–µ–∫—Ü–∏—è –ª–∏–Ω–∏–π –ø–∞—Ä–∫–æ–≤–æ—á–Ω–æ–π —Ä–∞–∑–º–µ—Ç–∫–∏
        
        Args:
            image: –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ø–∞—Ä–∫–æ–≤–∫–∏
        
        Returns:
            list: —Å–ø–∏—Å–æ–∫ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã—Ö –ª–∏–Ω–∏–π [(x1, y1, x2, y2), ...]
        """
        # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ grayscale
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        
        # –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ Gaussian blur –¥–ª—è —É–º–µ–Ω—å—à–µ–Ω–∏—è —à—É–º–∞
        blurred = cv2.GaussianBlur(gray, (5, 5), 0)
        
        # Edge detection (Canny)
        edges = cv2.Canny(blurred, self.canny_low, self.canny_high)
        
        # –ú–æ—Ä—Ñ–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–µ –æ–ø–µ—Ä–∞—Ü–∏–∏ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –ª–∏–Ω–∏–π
        kernel = np.ones((3, 3), np.uint8)
        edges = cv2.dilate(edges, kernel, iterations=1)
        edges = cv2.erode(edges, kernel, iterations=1)
        
        # –î–µ—Ç–µ–∫—Ü–∏—è –ª–∏–Ω–∏–π (Hough Transform)
        lines = cv2.HoughLinesP(
            edges,
            rho=1,
            theta=np.pi/180,
            threshold=self.hough_threshold,
            minLineLength=self.hough_min_line_length,
            maxLineGap=self.hough_max_line_gap
        )
        
        if lines is None:
            return []
        
        # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ —Ñ–æ—Ä–º–∞—Ç–∞
        detected_lines = []
        for line in lines:
            x1, y1, x2, y2 = line[0]
            detected_lines.append((x1, y1, x2, y2))
        
        return detected_lines
    
    def filter_vertical_lines(self, lines, angle_threshold=15):
        """
        –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –≤–µ—Ä—Ç–∏–∫–∞–ª—å–Ω—ã—Ö –ª–∏–Ω–∏–π (–≥—Ä–∞–Ω–∏—Ü—ã –ø–∞—Ä–∫–æ–≤–æ—á–Ω—ã—Ö –º–µ—Å—Ç)
        
        Args:
            lines: —Å–ø–∏—Å–æ–∫ –ª–∏–Ω–∏–π
            angle_threshold: –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ –æ—Ç –≤–µ—Ä—Ç–∏–∫–∞–ª–∏ (–≥—Ä–∞–¥—É—Å—ã)
        
        Returns:
            list: –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–µ –≤–µ—Ä—Ç–∏–∫–∞–ª—å–Ω—ã–µ –ª–∏–Ω–∏–∏
        """
        vertical_lines = []
        
        for x1, y1, x2, y2 in lines:
            # –í—ã—á–∏—Å–ª–µ–Ω–∏–µ —É–≥–ª–∞ –ª–∏–Ω–∏–∏
            angle = np.abs(np.arctan2(y2 - y1, x2 - x1) * 180 / np.pi)
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –≤–µ—Ä—Ç–∏–∫–∞–ª—å–Ω–æ—Å—Ç—å (—É–≥–æ–ª –±–ª–∏–∑–æ–∫ –∫ 90¬∞)
            if 90 - angle_threshold <= angle <= 90 + angle_threshold:
                vertical_lines.append((x1, y1, x2, y2))
        
        return vertical_lines
    
    def filter_horizontal_lines(self, lines, angle_threshold=15):
        """
        –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω—ã—Ö –ª–∏–Ω–∏–π (–≥—Ä–∞–Ω–∏—Ü—ã —Ä—è–¥–æ–≤)
        
        Args:
            lines: —Å–ø–∏—Å–æ–∫ –ª–∏–Ω–∏–π
            angle_threshold: –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ –æ—Ç –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª–∏ (–≥—Ä–∞–¥—É—Å—ã)
        
        Returns:
            list: –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–µ –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω—ã–µ –ª–∏–Ω–∏–∏
        """
        horizontal_lines = []
        
        for x1, y1, x2, y2 in lines:
            # –í—ã—á–∏—Å–ª–µ–Ω–∏–µ —É–≥–ª–∞ –ª–∏–Ω–∏–∏
            angle = np.abs(np.arctan2(y2 - y1, x2 - x1) * 180 / np.pi)
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω–æ—Å—Ç—å (—É–≥–æ–ª –±–ª–∏–∑–æ–∫ –∫ 0¬∞ –∏–ª–∏ 180¬∞)
            if angle <= angle_threshold or angle >= 180 - angle_threshold:
                horizontal_lines.append((x1, y1, x2, y2))
        
        return horizontal_lines
    
    def cluster_lines(self, lines, orientation='vertical'):
        """
        –ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è –ª–∏–Ω–∏–π –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –æ—Ç–¥–µ–ª—å–Ω—ã—Ö –≥—Ä–∞–Ω–∏—Ü –º–µ—Å—Ç
        
        Args:
            lines: —Å–ø–∏—Å–æ–∫ –ª–∏–Ω–∏–π
            orientation: 'vertical' –∏–ª–∏ 'horizontal'
        
        Returns:
            list: –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–æ–≤–∞–Ω–Ω—ã–µ –ª–∏–Ω–∏–∏ (—Å—Ä–µ–¥–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è)
        """
        if not lines:
            return []
        
        # –í—ã–±–æ—Ä –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –¥–ª—è –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏
        if orientation == 'vertical':
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º X –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—É (—Å—Ä–µ–¥–Ω—é—é)
            coords = np.array([[(x1 + x2) / 2] for x1, y1, x2, y2 in lines])
        else:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º Y –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—É (—Å—Ä–µ–¥–Ω—é—é)
            coords = np.array([[(y1 + y2) / 2] for x1, y1, x2, y2 in lines])
        
        # DBSCAN –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è
        clustering = DBSCAN(eps=self.dbscan_eps, min_samples=self.dbscan_min_samples)
        labels = clustering.fit_predict(coords)
        
        # –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –ø–æ –∫–ª–∞—Å—Ç–µ—Ä–∞–º
        clustered_lines = []
        for label in set(labels):
            if label == -1:  # –®—É–º
                continue
            
            cluster_indices = np.where(labels == label)[0]
            cluster_lines = [lines[i] for i in cluster_indices]
            
            # –í—ã—á–∏—Å–ª–µ–Ω–∏–µ —Å—Ä–µ–¥–Ω–µ–π –ª–∏–Ω–∏–∏ –∫–ª–∞—Å—Ç–µ—Ä–∞
            if orientation == 'vertical':
                avg_x = np.mean([[(x1 + x2) / 2] for x1, y1, x2, y2 in cluster_lines])
                min_y = min([min(y1, y2) for x1, y1, x2, y2 in cluster_lines])
                max_y = max([max(y1, y2) for x1, y1, x2, y2 in cluster_lines])
                clustered_lines.append((int(avg_x), int(min_y), int(avg_x), int(max_y)))
            else:
                avg_y = np.mean([[(y1 + y2) / 2] for x1, y1, x2, y2 in cluster_lines])
                min_x = min([min(x1, x2) for x1, y1, x2, y2 in cluster_lines])
                max_x = max([max(x1, x2) for x1, y1, x2, y2 in cluster_lines])
                clustered_lines.append((int(min_x), int(avg_y), int(max_x), int(avg_y)))
        
        return clustered_lines
    
    def generate_parking_spaces(self, vertical_lines, horizontal_lines, image_shape):
        """
        –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø–∞—Ä–∫–æ–≤–æ—á–Ω—ã—Ö –º–µ—Å—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤–µ—Ä—Ç–∏–∫–∞–ª—å–Ω—ã—Ö –∏ –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω—ã—Ö –ª–∏–Ω–∏–π
        
        Args:
            vertical_lines: –≤–µ—Ä—Ç–∏–∫–∞–ª—å–Ω—ã–µ –≥—Ä–∞–Ω–∏—Ü—ã
            horizontal_lines: –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω—ã–µ –≥—Ä–∞–Ω–∏—Ü—ã
            image_shape: —Ä–∞–∑–º–µ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (height, width)
        
        Returns:
            list: —Å–ø–∏—Å–æ–∫ –ø–∞—Ä–∫–æ–≤–æ—á–Ω—ã—Ö –º–µ—Å—Ç [(x, y, width, height), ...]
        """
        parking_spaces = []
        
        # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ª–∏–Ω–∏–π
        vertical_lines = sorted(vertical_lines, key=lambda l: (l[0] + l[2]) / 2)
        horizontal_lines = sorted(horizontal_lines, key=lambda l: (l[1] + l[3]) / 2)
        
        height, width = image_shape[:2]
        
        # –ï—Å–ª–∏ –Ω–µ—Ç –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω—ã—Ö –ª–∏–Ω–∏–π, –∏—Å–ø–æ–ª—å–∑—É–µ–º –≥—Ä–∞–Ω–∏—Ü—ã –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        if not horizontal_lines:
            horizontal_lines = [(0, 0, width, 0), (0, height, width, height)]
        
        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –º–µ—Å—Ç –Ω–∞ –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏—è—Ö
        for i in range(len(vertical_lines) - 1):
            x1_line = vertical_lines[i]
            x2_line = vertical_lines[i + 1]
            
            x1 = int((x1_line[0] + x1_line[2]) / 2)
            x2 = int((x2_line[0] + x2_line[2]) / 2)
            
            space_width = x2 - x1
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —Ä–∞–∑—É–º–Ω—É—é —à–∏—Ä–∏–Ω—É –º–µ—Å—Ç–∞
            if not (self.min_space_width <= space_width <= self.max_space_width):
                continue
            
            for j in range(len(horizontal_lines) - 1):
                y1_line = horizontal_lines[j]
                y2_line = horizontal_lines[j + 1]
                
                y1 = int((y1_line[1] + y1_line[3]) / 2)
                y2 = int((y2_line[1] + y2_line[3]) / 2)
                
                space_height = y2 - y1
                
                # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —Ä–∞–∑—É–º–Ω—É—é –≤—ã—Å–æ—Ç—É
                if space_height < 100:
                    continue
                
                parking_spaces.append({
                    'x': x1,
                    'y': y1,
                    'width': space_width,
                    'height': space_height,
                    'center': (x1 + space_width // 2, y1 + space_height // 2)
                })
        
        return parking_spaces
    
    def auto_detect_spaces(self, image, visualize=False):
        """
        –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –≤—Å–µ—Ö –ø–∞—Ä–∫–æ–≤–æ—á–Ω—ã—Ö –º–µ—Å—Ç
        
        Args:
            image: –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ø–∞—Ä–∫–æ–≤–∫–∏
            visualize: –ø–æ–∫–∞–∑–∞—Ç—å –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        
        Returns:
            list: —Å–ø–∏—Å–æ–∫ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã—Ö –ø–∞—Ä–∫–æ–≤–æ—á–Ω—ã—Ö –º–µ—Å—Ç
        """
        print("\n" + "="*60)
        print("  –ê–í–¢–û–ú–ê–¢–ò–ß–ï–°–ö–û–ï –û–ë–ù–ê–†–£–ñ–ï–ù–ò–ï –ü–ê–†–ö–û–í–û–ß–ù–´–• –ú–ï–°–¢")
        print("="*60 + "\n")
        
        # –®–∞–≥ 1: –î–µ—Ç–µ–∫—Ü–∏—è –≤—Å–µ—Ö –ª–∏–Ω–∏–π
        print("1. –î–µ—Ç–µ–∫—Ü–∏—è –ª–∏–Ω–∏–π —Ä–∞–∑–º–µ—Ç–∫–∏...")
        all_lines = self.detect_parking_lines(image)
        print(f"   –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ –ª–∏–Ω–∏–π: {len(all_lines)}")
        
        if not all_lines:
            print("‚ùå –õ–∏–Ω–∏–∏ –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω—ã")
            return []
        
        # –®–∞–≥ 2: –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –≤–µ—Ä—Ç–∏–∫–∞–ª—å–Ω—ã—Ö –ª–∏–Ω–∏–π
        print("\n2. –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –≤–µ—Ä—Ç–∏–∫–∞–ª—å–Ω—ã—Ö –ª–∏–Ω–∏–π...")
        vertical_lines = self.filter_vertical_lines(all_lines)
        print(f"   –í–µ—Ä—Ç–∏–∫–∞–ª—å–Ω—ã—Ö –ª–∏–Ω–∏–π: {len(vertical_lines)}")
        
        # –®–∞–≥ 3: –ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è –≤–µ—Ä—Ç–∏–∫–∞–ª—å–Ω—ã—Ö –ª–∏–Ω–∏–π
        print("\n3. –ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è –≤–µ—Ä—Ç–∏–∫–∞–ª—å–Ω—ã—Ö –ª–∏–Ω–∏–π...")
        clustered_vertical = self.cluster_lines(vertical_lines, 'vertical')
        print(f"   –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –≥—Ä–∞–Ω–∏—Ü: {len(clustered_vertical)}")
        
        # –®–∞–≥ 4: –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω—ã—Ö –ª–∏–Ω–∏–π
        print("\n4. –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω—ã—Ö –ª–∏–Ω–∏–π...")
        horizontal_lines = self.filter_horizontal_lines(all_lines)
        print(f"   –ì–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω—ã—Ö –ª–∏–Ω–∏–π: {len(horizontal_lines)}")
        
        # –®–∞–≥ 5: –ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω—ã—Ö –ª–∏–Ω–∏–π
        print("\n5. –ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω—ã—Ö –ª–∏–Ω–∏–π...")
        clustered_horizontal = self.cluster_lines(horizontal_lines, 'horizontal')
        print(f"   –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Ä—è–¥–æ–≤: {len(clustered_horizontal)}")
        
        # –®–∞–≥ 6: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø–∞—Ä–∫–æ–≤–æ—á–Ω—ã—Ö –º–µ—Å—Ç
        print("\n6. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø–∞—Ä–∫–æ–≤–æ—á–Ω—ã—Ö –º–µ—Å—Ç...")
        self.parking_spaces = self.generate_parking_spaces(
            clustered_vertical,
            clustered_horizontal,
            image.shape
        )
        print(f"   –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ –º–µ—Å—Ç: {len(self.parking_spaces)}")
        
        # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
        if visualize:
            self._visualize_detection(
                image,
                all_lines,
                clustered_vertical,
                clustered_horizontal,
                self.parking_spaces
            )
        
        print("\n" + "="*60)
        print("  ‚úÖ –û–ë–ù–ê–†–£–ñ–ï–ù–ò–ï –ó–ê–í–ï–†–®–ï–ù–û")
        print("="*60 + "\n")
        
        return self.parking_spaces
    
    def _visualize_detection(self, image, all_lines, vertical_lines, 
                           horizontal_lines, parking_spaces):
        """–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–æ—Ü–µ—Å—Å–∞ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è"""
        
        # –í—Å–µ –ª–∏–Ω–∏–∏
        img_all_lines = image.copy()
        for x1, y1, x2, y2 in all_lines:
            cv2.line(img_all_lines, (x1, y1), (x2, y2), (0, 255, 0), 1)
        
        # –ö–ª–∞—Å—Ç–µ—Ä–∏–∑–æ–≤–∞–Ω–Ω—ã–µ –ª–∏–Ω–∏–∏
        img_clustered = image.copy()
        for x1, y1, x2, y2 in vertical_lines:
            cv2.line(img_clustered, (x1, y1), (x2, y2), (0, 0, 255), 2)
        for x1, y1, x2, y2 in horizontal_lines:
            cv2.line(img_clustered, (x1, y1), (x2, y2), (255, 0, 0), 2)
        
        # –ü–∞—Ä–∫–æ–≤–æ—á–Ω—ã–µ –º–µ—Å—Ç–∞
        img_spaces = image.copy()
        for i, space in enumerate(parking_spaces):
            x, y, w, h = space['x'], space['y'], space['width'], space['height']
            cv2.rectangle(img_spaces, (x, y), (x + w, y + h), (255, 0, 255), 2)
            cv2.putText(img_spaces, str(i+1), (x + 5, y + 20),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
        output_dir = Path('outputs/auto_detection')
        output_dir.mkdir(parents=True, exist_ok=True)
        
        cv2.imwrite(str(output_dir / 'step1_all_lines.jpg'), img_all_lines)
        cv2.imwrite(str(output_dir / 'step2_clustered_lines.jpg'), img_clustered)
        cv2.imwrite(str(output_dir / 'step3_parking_spaces.jpg'), img_spaces)
        
        print(f"\nüìÅ –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ {output_dir}")
    
    def check_occupancy(self, image, vehicle_detections):
        """
        –ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞–Ω—è—Ç–æ—Å—Ç–∏ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã—Ö –º–µ—Å—Ç
        
        Args:
            image: –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            vehicle_detections: –¥–µ—Ç–µ–∫—Ü–∏–∏ –æ—Ç YOLOv8
        
        Returns:
            dict: –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –∑–∞–Ω—è—Ç–æ—Å—Ç–∏ –º–µ—Å—Ç
        """
        if not self.parking_spaces:
            print("‚ö†Ô∏è –°–Ω–∞—á–∞–ª–∞ –≤—ã–ø–æ–ª–Ω–∏—Ç–µ auto_detect_spaces()")
            return None
        
        occupied_count = 0
        free_count = 0
        spaces_status = []
        
        for i, space in enumerate(self.parking_spaces):
            x, y, w, h = space['x'], space['y'], space['width'], space['height']
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏—è —Å –¥–µ—Ç–µ–∫—Ü–∏—è–º–∏ —Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç–∞
            is_occupied = self._check_vehicle_overlap(x, y, w, h, vehicle_detections)
            
            if is_occupied:
                occupied_count += 1
                status = 'occupied'
            else:
                free_count += 1
                status = 'free'
            
            spaces_status.append({
                'id': i,
                'position': (x, y),
                'width': w,
                'height': h,
                'center': space['center'],
                'status': status,
                'has_vehicle': is_occupied
            })
        
        total_spaces = len(self.parking_spaces)
        occupancy_rate = (occupied_count / total_spaces * 100) if total_spaces > 0 else 0
        
        return {
            'total_spaces': total_spaces,
            'occupied': occupied_count,
            'free': free_count,
            'occupancy_rate': round(occupancy_rate, 1),
            'spaces': spaces_status
        }
    
    def _check_vehicle_overlap(self, space_x, space_y, space_w, space_h, vehicle_detections):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏—è –º–µ—Å—Ç–∞ —Å –¥–µ—Ç–µ–∫—Ü–∏—è–º–∏ —Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç–∞"""
        space_rect = (space_x, space_y, space_x + space_w, space_y + space_h)
        
        for vehicle in vehicle_detections:
            vehicle_rect = (vehicle['x1'], vehicle['y1'], vehicle['x2'], vehicle['y2'])
            
            if self._rectangles_overlap(space_rect, vehicle_rect):
                return True
        
        return False
    
    def _rectangles_overlap(self, rect1, rect2):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏—è –ø—Ä—è–º–æ—É–≥–æ–ª—å–Ω–∏–∫–æ–≤"""
        x1_min, y1_min, x1_max, y1_max = rect1
        x2_min, y2_min, x2_max, y2_max = rect2
        
        return not (x1_max < x2_min or x2_max < x1_min or 
                   y1_max < y2_min or y2_max < y1_min)
    
    def draw_spaces(self, image, spaces_status):
        """–û—Ç—Ä–∏—Å–æ–≤–∫–∞ –ø–∞—Ä–∫–æ–≤–æ—á–Ω—ã—Ö –º–µ—Å—Ç"""
        result = image.copy()
        
        for space in spaces_status:
            x, y = space['position']
            w, h = space['width'], space['height']
            status = space['status']
            
            # –¶–≤–µ—Ç –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Å—Ç–∞—Ç—É—Å–∞
            if status == 'occupied':
                color = (0, 0, 255)  # –ö—Ä–∞—Å–Ω—ã–π
            else:
                color = (0, 255, 0)  # –ó–µ–ª–µ–Ω—ã–π
            
            # –†–∏—Å—É–µ–º –ø—Ä—è–º–æ—É–≥–æ–ª—å–Ω–∏–∫
            cv2.rectangle(result, (x, y), (x + w, y + h), color, 2)
            
            # –ù–æ–º–µ—Ä –º–µ—Å—Ç–∞
            cv2.putText(result, str(space['id'] + 1), (x + 5, y + 20),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)
        
        return result
    
    def save_spaces(self, filename='config/auto_detected_spaces.pkl'):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã—Ö –º–µ—Å—Ç"""
        filepath = Path(filename)
        filepath.parent.mkdir(parents=True, exist_ok=True)
        
        with open(filepath, 'wb') as f:
            pickle.dump(self.parking_spaces, f)
        
        print(f"‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ {len(self.parking_spaces)} –º–µ—Å—Ç –≤ {filepath}")
    
    def load_spaces(self, filename='config/auto_detected_spaces.pkl'):
        """–ó–∞–≥—Ä—É–∑–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã—Ö –º–µ—Å—Ç"""
        filepath = Path(filename)
        
        if not filepath.exists():
            print(f"‚ùå –§–∞–π–ª {filepath} –Ω–µ –Ω–∞–π–¥–µ–Ω")
            return False
        
        with open(filepath, 'rb') as f:
            self.parking_spaces = pickle.load(f)
        
        print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(self.parking_spaces)} –º–µ—Å—Ç –∏–∑ {filepath}")
        return True


# ============ –¢–ï–°–¢ ============
if __name__ == "__main__":
    # –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
    detector = AutomaticParkingDetector()
    
    # –ü—É—Ç—å –∫ —Ç–µ—Å—Ç–æ–≤–æ–º—É –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é
    test_image_path = 'test_images/parking_lot.jpg'
    
    if Path(test_image_path).exists():
        # –ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        image = cv2.imread(test_image_path)
        
        # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –º–µ—Å—Ç
        spaces = detector.auto_detect_spaces(image, visualize=True)
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        if spaces:
            detector.save_spaces()
            detector.save_config()
        
        print(f"\nüìä –ò–¢–û–ì–û: –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ {len(spaces)} –ø–∞—Ä–∫–æ–≤–æ—á–Ω—ã—Ö –º–µ—Å—Ç")
    else:
        print(f"‚ùå –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ: {test_image_path}")
